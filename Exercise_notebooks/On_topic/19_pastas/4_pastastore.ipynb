{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pastastore\n",
    "\n",
    "In this notebook you will learn:\n",
    "- what a pastastore is (within the context of the Pastas Python package).\n",
    "- how observations series, stresses and models are stored in a pastastore.\n",
    "- how to do bulk operations on pastastores.\n",
    "- how to write and read a pastastores from a file.\n",
    "\n",
    "\n",
    "In order to do bulk operations on time series models you can use a Pastastore. A Pastastore is an object that can contain observations, stresses and models at multiple observation points. The object has convenient methods to store time series data, create models, add stressmodels and summarize the results. This notebook gives a brief overview of the current possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First perform the necessary imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pastas as ps\n",
    "import pastastore as pst\n",
    "import hydropandas as hpd\n",
    "from packaging import version\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.set_log_level(\"ERROR\")\n",
    "if version.parse(ps.__version__) < version.parse(\"0.16.0\"):\n",
    "    raise RuntimeError(\n",
    "        f\"this notebook is not working for pastas versions lower than 0.17.0, your version is {ps.__version__}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty Pastastore\n",
    "conn = pst.DictConnector(\"pastastore\")\n",
    "store = pst.PastaStore(conn)\n",
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "We can add observation (oseries) to the pastastore using the `store.add_oseries` method. Observations are added to `store.oseries`, which is a Pandas DataFrame. Metadata provided to `pst.add_oseries` is shown in the other columns of `store.oseries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the observations in all the files in the data-directory that end with _1.csv\n",
    "datapath = r\"data/nb4\"\n",
    "files = [x for x in os.listdir(datapath) if x.endswith(\"_1.csv\")]\n",
    "for file in files:\n",
    "    fname = os.path.join(datapath, file)\n",
    "    series = hpd.GroundwaterObs.from_dino(fname)\n",
    "    store.add_oseries(\n",
    "        series[\"stand_m_tov_nap\"].dropna(),\n",
    "        name=series.name,\n",
    "        metadata={\"x\": series.x, \"y\": series.y},\n",
    "    )\n",
    "\n",
    "# show the contents of pr.oseries\n",
    "store.oseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 <a name=\"ex1\"></a>\n",
    "Create a pastastore. Add the observations in the `data/nb4/ex1` directory to the model. Which measurements series has the lowest filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ans1\">Answer Exercise 1</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stresses\n",
    "We can also add stresses to a pastastore using the `store.add_stress` method. We use the `kind=` argument to tell what kind of stress we add. We add the precipitation-series as `kind='prec'` and the evaporation-series as `kind='evap'`. Stresses are added to `store.stresses`, which is a Pandas DataFrame (just like `store.oseries`). Metadata provided to add_series is shown in the other columns of `store.stresses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add evaporation\n",
    "fname = os.path.join(datapath, \"etmgeg_391.txt\")\n",
    "series = hpd.MeteoObs.from_knmi(\"EV24\", fname=fname)\n",
    "series.index = pd.to_datetime(series.index.date)\n",
    "store.add_stress(\n",
    "    series.squeeze(),\n",
    "    name=series.name,\n",
    "    kind=\"evap\",\n",
    "    metadata={\"x\": float(series.x), \"y\": float(series.y)},\n",
    ")\n",
    "\n",
    "# add precipitation\n",
    "fname = os.path.join(datapath, \"KNMI_Akkrum.txt\")\n",
    "series = hpd.MeteoObs.from_knmi(\"RD\", fname=fname, fill_missing_obs=True)\n",
    "series.index = pd.to_datetime(series.index.date)\n",
    "store.add_stress(\n",
    "    series.squeeze(),\n",
    "    name=series.name,\n",
    "    kind=\"prec\",\n",
    "    metadata={\"x\": float(series.x), \"y\": float(series.y)},\n",
    ")\n",
    "\n",
    "# show the stresses inside the pastastore\n",
    "store.stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 <a name=\"ex2\"></a>\n",
    "Add the evaporation from De Bilt and the precipitation from Akkrum to the pastastore that you made in Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ans2\">Answer Exercise 2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "In a pastastore you can create time series models from the observations and add recharge. Models are added to `store.models`, which is a list with the model-names. The `add_recharge=True` adds a recharge stress to the model based on the precipitation- and evaporation-series closest to the location of the model's oseries.\n",
    "\n",
    "The file that we used for precipitation did not contain any coordinates, which will therefore default to 0.0. The evaporation-file contains coordinates in epsg:4326, while our observation-files contain coordinates in epsg:28992. Right now we do not transform coordinates. So finding the closest precipitation- and evaporation-series will normally give wrong results. As we have only one precipitation and evaporation series however, this is not a problem.\n",
    "\n",
    "In the code-section below, we make 11 models with recharge and solve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in store.oseries.index:\n",
    "    ml = store.create_model(name, add_recharge=True)\n",
    "    ml.solve(report=False)\n",
    "    store.add_model(ml, overwrite=True)\n",
    "\n",
    "# show the contents of pr.models\n",
    "store.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 <a name=\"ex3\"></a>\n",
    "Create models of the oseries in your pastastore from exercise 2 and solve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ans3\">Answer Exercise 3</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot individual results\n",
    "Take one of the models and plot the decomposition. As we can see, the precipitation series does not contain the first few years of the simulation. The start- and end-dates of the model (tmin and tmax) are solely determined by the observation-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"B32D0136-001\"\n",
    "ml = store.get_models(name)\n",
    "ml.plots.decomposition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some statistics / parameters of all models\n",
    "Make a table with some statistics of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.get_statistics([\"evp\", \"aic\"]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a table with some parameters of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.get_parameters([\"recharge_A\", \"constant_d\", \"noise_alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4 <a name=\"ex4\"></a>\n",
    "Get the EVP from the models in your pastastore from exercise 3. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ans4\">Answer Exercise 4</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5 <a name=\"ex5\"></a>\n",
    "\n",
    "Improve the models in your pastastore from exercise 4 by:\n",
    "- replacing the precipitation from Akkrum with measurements from IJsselstein. Use this website to obtain the data https://www.knmi.nl/nederland-nu/klimatologie/monv/reeksen. \n",
    "- replacing the evaporation from De Bilt with the evaporation from Arcen using this website https://www.knmi.nl/nederland-nu/klimatologie/daggegevens. \n",
    "\n",
    "Does this improve the EVP? Plot the results of model B52D0502_1, what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ans5\">Answer Exercise 5</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6 <a name=\"ex6\"></a>\n",
    "There are no evaporation measurements at Arcen before 1991. Change the calibration period of the models using tmin in such a way that a more realistic model is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ans6\">Answer Exercise 6</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7 <a name=\"ex7\"></a>\n",
    "Add a step trend to the models in january 2010. Solve the models and explore the results. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#ans7\">Answer Exercise 7</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and reading pastastores\n",
    "We can save an entire pastastore, with all its series and models, to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store.to_zip(\"pastasstore.zip\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we can reload this pastastore again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pst.DictConnector(\"pastastore\")\n",
    "pst.PastaStore.from_zip(\"pastasstore.zip\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if everything went ok by plotting the decomposition of B32D0136-001 again. This figure is exactly the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"B32D0136-001\"\n",
    "ml = store.get_models(name)\n",
    "ml.plots.decomposition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"#ex1\">Answer exercise 1</a> <a name=\"ans1\"></a>\n",
    "\n",
    "Measurement point B52D0192_2 has the lowest filter. This can be seen in the column `Onderkant filter (cm t.o.v. NAP)` from the dataframe: `pr_q.oseries`. This is a hard question if you don't know Dutch (sorry!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add the observations in all the files in the data-directory that end with _1.csv\n",
    "conn2 = pst.DictConnector(\"data_nb4\")\n",
    "store2 = pst.PastaStore(conn2)\n",
    "\n",
    "datapath2 = r\"data/nb4/ex1\"\n",
    "files = [x for x in os.listdir(datapath2) if x.endswith(\"_1.csv\")]\n",
    "for file in files:\n",
    "    fname = os.path.join(datapath2, file)\n",
    "    series = hpd.GroundwaterObs.from_dino(fname)\n",
    "    store2.add_oseries(\n",
    "        series[\"stand_m_tov_nap\"],\n",
    "        name=series.name,\n",
    "        metadata={\"x\": series.x, \"y\": series.y},\n",
    "    )\n",
    "\n",
    "# show the contents of pr.oseries\n",
    "store2.oseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"#ex2\">Answer exercise 2</a> <a name=\"ans2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath2 = r\"data/nb4\"\n",
    "\n",
    "# add evaporation\n",
    "fname = os.path.join(datapath, \"etmgeg_391.txt\")\n",
    "series = hpd.MeteoObs.from_knmi(\"EV24\", fname=fname)\n",
    "series.index = pd.to_datetime(series.index.date)\n",
    "store2.add_stress(\n",
    "    series,\n",
    "    name=series.name,\n",
    "    kind=\"evap\",\n",
    "    metadata={\"x\": float(series.x), \"y\": float(series.y)},\n",
    ")\n",
    "\n",
    "# add precipitation\n",
    "fname = os.path.join(datapath, \"KNMI_Akkrum.txt\")\n",
    "series = hpd.MeteoObs.from_knmi(\"RD\", fname=fname)\n",
    "series.index = pd.to_datetime(series.index.date)\n",
    "store2.add_stress(\n",
    "    series,\n",
    "    name=series.name,\n",
    "    kind=\"prec\",\n",
    "    metadata={\"x\": float(series.x), \"y\": float(series.y)},\n",
    ")\n",
    "\n",
    "# show the contents of pr.stresses\n",
    "store2.stresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"#ex3\">Answer exercise 3</a> <a name=\"ans3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store2.oseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative with a for-loop\n",
    "for name in store2.oseries.index:\n",
    "    ml = store2.create_model(name, add_recharge=True)\n",
    "    ml.solve(report=False)\n",
    "    store2.add_model(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"#ex4\">Answer exercise 4</a> <a name=\"ans4\"></a>\n",
    "\n",
    "See the explained variance (evp) in the cell below. The evp is rather low. In general people use an evp value of more than 70-80% for a reasonable fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store2.get_statistics([\"evp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"#ex5\">Answer exercise 5</a> <a name=\"ans5\"></a>\n",
    "\n",
    "The evaporation time series of IJsselstein has no values before 1991 and therefore the model of B52D0502_1 and others have a poor fit/low evp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add precipitation\n",
    "fname = os.path.join(datapath, \"neerslaggeg_IJSSELSTEYN-L_913.txt\")\n",
    "series = hpd.MeteoObs.from_knmi(\"RD\", fname=fname)\n",
    "series.index = pd.to_datetime(series.index.date)\n",
    "store2.add_stress(\n",
    "    series,\n",
    "    name=series.name,\n",
    "    kind=\"prec\",\n",
    "    metadata={\"x\": float(series.x), \"y\": float(series.y)},\n",
    ")\n",
    "\n",
    "\n",
    "# delete existing stresses\n",
    "store2.del_stress(\"RD_AKKRUM\")\n",
    "\n",
    "# create and solve the models\n",
    "for name in store2.oseries.index:\n",
    "    ml = store2.create_model(name, add_recharge=True)\n",
    "    ml.solve(report=False)\n",
    "    store2.add_model(ml, overwrite=True)\n",
    "\n",
    "\n",
    "# get the statistics\n",
    "print(store2.get_statistics([\"evp\"]))\n",
    "\n",
    "# results of individual model\n",
    "name = \"B52D0502-001\"\n",
    "ml = store2.get_models(name)\n",
    "ml.plots.decomposition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"#ex6\">Answer exercise 6</a> <a name=\"ans6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in store2.oseries.index:\n",
    "    ml = store2.create_model(name, add_recharge=True)\n",
    "    ml.solve(tmin=\"1993\", report=False)\n",
    "    store2.add_model(ml, overwrite=True)\n",
    "\n",
    "print(store2.get_statistics([\"evp\"]))\n",
    "\n",
    "# results of individual model\n",
    "name = \"B52D0502-001\"\n",
    "ml = store2.get_models(name)\n",
    "ml.plots.decomposition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a href=\"#ex7\">Answer exercise 7</a> <a name=\"ans7\"></a>\n",
    "\n",
    "There seems to be little effect of the steptrend on the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = ps.stressmodels.StepModel(\"2010\", name=\"step\", up=True)\n",
    "sm2 = ps.stressmodels.StepModel(\"2013\", name=\"step2\", up=True)\n",
    "\n",
    "for name in store2.oseries.index:\n",
    "    ml = store2.create_model(name, add_recharge=True)\n",
    "    ml.add_stressmodel(sm)\n",
    "    # ml.add_stressmodel(sm2)\n",
    "    ml.solve(tmin=\"1993\", report=False)\n",
    "    store2.add_model(ml, overwrite=True)\n",
    "\n",
    "print(store2.get_statistics([\"evp\"]))\n",
    "\n",
    "# results of individual model\n",
    "name = \"B52D0502-001\"\n",
    "ml = store2.get_models(name)\n",
    "ml.plots.decomposition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paotm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
